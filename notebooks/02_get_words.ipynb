{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get/Generate words for search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 Installing needed packages\n",
    "\n",
    "When running on a remote JupyterLab, packages that are needed have to be explicitly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pandas==2.1.4\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocess data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.read_csv(\"../data/tables/names.csv\", sep=\",\")\n",
    "\n",
    "# drop merged columns\n",
    "names_df.drop(\n",
    "    labels=[\n",
    "        \"note\",\n",
    "        \"source\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 Remove rows with empty greek label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_df.dropna(subset=[\"label:el\"], how=\"any\", inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remove diacritics\n",
    "As the transcripted text contains no accents and is completely lowercase, diacritcs have to be removed from data collected on persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"label:el\",\n",
    "    \"label:el:norm\",\n",
    "    \"Nom Sg\",\n",
    "    \"Gen Sg\",\n",
    "    \"Dat Sg\",\n",
    "    \"Akk Sg\",\n",
    "    \"Voc Sg\",\n",
    "    \"alternatives\",\n",
    "]\n",
    "\n",
    "def str_remove_diacritics(s: str) -> str:\n",
    "    return \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFKD\", s)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    ).lower()\n",
    "\n",
    "# remove diacritics from all columns named in columns_to_process\n",
    "for col in columns:\n",
    "    names_df[col] = names_df[col].apply(\n",
    "        lambda x: str_remove_diacritics(x) if pd.notnull(x) else x\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 Merging column data\n",
    "\n",
    "All cases and alternative spellings get merged into a column named 'variants' to remove identical forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to merge columns\n",
    "def columns_to_set(row) -> set:\n",
    "    filtered_list = [e for elem in row if pd.notnull(elem) for e in elem.split(',')]\n",
    "    return set(filtered_list)\n",
    "\n",
    "\n",
    "columns = [\n",
    "    \"label:el\",\n",
    "    \"label:el:norm\",\n",
    "    \"Nom Sg\",\n",
    "    \"Gen Sg\",\n",
    "    \"Dat Sg\",\n",
    "    \"Akk Sg\",\n",
    "    \"Voc Sg\",\n",
    "    \"alternatives\",\n",
    "]\n",
    "\n",
    "# Applying the function to merge columns\n",
    "names_df[\"variants\"] = names_df[columns].apply(columns_to_set, axis=1)\n",
    "\n",
    "# drop merged columns\n",
    "names_df.drop(\n",
    "    labels=[\n",
    "        \"label:el\",\n",
    "        \"Nom Sg\",\n",
    "        \"Gen Sg\",\n",
    "        \"Dat Sg\",\n",
    "        \"Akk Sg\",\n",
    "        \"Voc Sg\",\n",
    "        \"alternatives\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Add type (future use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names_df[\"type\"] = \"name\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Explode by name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# add index for words\n",
    "names_df[\"wordID\"] = range(0, len(names_df))\n",
    "names_df = names_df.rename(columns={'variants': 'variant'})\n",
    "# explode name_df by column variant\n",
    "names_df = names_df.explode(\"variant\").reset_index()\n",
    "# Adding a new column 'variantID' with unique numbers for each variant (row)\n",
    "names_df[\"variantID\"] = range(0, len(names_df))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.6 Remove factgrid link to keep entity numbers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split factgrid string on ,\n",
    "# Splitting strings in the column based on comma and converting them into sets\n",
    "names_df[\"factgrid\"] = (\n",
    "    names_df[\"factgrid\"].astype(str).apply(lambda x: set(x.split(\",\")))\n",
    ")\n",
    "# Exploding the sets in the column\n",
    "names_df = names_df.explode(\"factgrid\")\n",
    "# Removing the substring from all strings in the column\n",
    "names_df[\"factgrid\"] = names_df[\"factgrid\"].str.replace(\n",
    "    \"https://database.factgrid.de/entity/\", \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop not needed column index (as it has already been updated) from dataframe\n",
    "names_df.drop(columns=[\"index\"], inplace=True)\n",
    "# write to csv file\n",
    "names_df.to_csv(\"../data/names.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
