{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f61595",
   "metadata": {},
   "source": [
    "# Parsing JSON files\n",
    "\n",
    "## 1 Installing and importing needed modules\n",
    "\n",
    "When running on a remote JupyterLab, packages that are needed have to be explicitly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pandas==2.1.4\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from glob import glob\n",
    "from utils import docID_to_ga\n",
    "\n",
    "# read file manuscripts_tei.csv\n",
    "manuscripts_tei_df = pd.read_csv(\n",
    "    \"../data/manuscripts_tei.csv\",\n",
    "    low_memory=False,\n",
    "    usecols=[\"docID\", \"ga\", \"label\", \"source\"],\n",
    "    dtype={\n",
    "        \"docID\": \"int32\",\n",
    "        \"ga\": \"string\",\n",
    "        \"label\": \"string\",\n",
    "        \"source\": \"string\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716d132bbbbd596",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 Process JSON files in parallel\n",
    "\n",
    "Currently, we only take docID, ga, pagesCount, and estimated originYear/century. BUT there is way more data for each page/image etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7cd601739d268",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to process each JSON file and extract information\n",
    "def process_json_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Initialize all values to NaN\n",
    "    docID = (\n",
    "        originYearLate\n",
    "    ) = (\n",
    "        originYearEarly\n",
    "    ) = century = pagesCount = ga = leavesCount = shelf_instances = float(\"nan\")\n",
    "\n",
    "    # try to fill variables with values\n",
    "    docID = json_data[\"data\"][\"manuscript\"][\"docID\"]\n",
    "    originYearLate = json_data[\"data\"][\"manuscript\"][\"originYear\"][\"late\"]\n",
    "    originYearEarly = json_data[\"data\"][\"manuscript\"][\"originYear\"][\"early\"]\n",
    "    pagesCount = json_data[\"data\"][\"manuscript\"][\"pages\"][\"count\"]\n",
    "    leavesCount = json_data[\"data\"][\"manuscript\"][\"leaves\"][\"leavesCount\"]\n",
    "    ga = docID_to_ga(\n",
    "        docID\n",
    "    )  # BUG: json_data[\"data\"][\"manuscript\"][\"leaves\"][\"gaNum\"] for 20000 and 30000 identical FIX: wrote own function\n",
    "\n",
    "    # sometime no shelf index is given\n",
    "    try:\n",
    "        shelf_instances_data = json_data[\"data\"][\"manuscript\"][\"shelfInstances\"][\n",
    "            \"shelfInstance\"\n",
    "        ]\n",
    "        if isinstance(shelf_instances_data, list):\n",
    "            shelf_instances = [\n",
    "                {k: v for k, v in instance.items() if v != \"\"}\n",
    "                for instance in shelf_instances_data\n",
    "            ]\n",
    "        elif isinstance(\n",
    "            shelf_instances_data, dict\n",
    "        ):  # Clean and convert a single dictionary to a list of dictionaries\n",
    "            shelf_instances = [\n",
    "                {k: v for k, v in shelf_instances_data.items() if v != \"\"}\n",
    "            ]\n",
    "        else:\n",
    "            shelf_instances = []\n",
    "    except:\n",
    "        shelf_instances = None\n",
    "\n",
    "    # sometimes century is not given\n",
    "    try:\n",
    "        century = json_data[\"data\"][\"manuscript\"][\"originYear\"][\"content\"]\n",
    "    except:\n",
    "        century = None\n",
    "\n",
    "    return {\n",
    "        \"docID\": docID,\n",
    "        \"originYearLate\": originYearLate,\n",
    "        \"originYearEarly\": originYearEarly,\n",
    "        \"pagesCount\": pagesCount,\n",
    "        \"leavesCount\": leavesCount,\n",
    "        \"ga\": ga,\n",
    "        \"century\": century,\n",
    "        \"shelfInstances\": shelf_instances,\n",
    "        \"source\": \"ntvmr\",\n",
    "    }\n",
    "\n",
    "\n",
    "# List of JSON files\n",
    "json_files = glob(\"../data/manuscripts/ntvmr/*.json\")\n",
    "\n",
    "# Process JSON files in parallel using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_json_file, json_files))\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "manuscripts_json_df = pd.DataFrame(results)\n",
    "manuscripts_json_df.to_csv(\"../data/manuscripts_json.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693d3bd3dd95ada",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manuscripts_json_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06575d4fd2e5f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manuscripts_tei_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7d8caf4e2b02e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 Merge\n",
    "Here we merge the just generated data with the already found data from teiparse.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f23aad3f87938",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([manuscripts_json_df, manuscripts_tei_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e0fc12efacfaf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4 Writing to file\n",
    "\n",
    "Before writing to file pagesCount should be set to be integer, therefor NaN values are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac332c929b8cc72",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_df[\"pagesCount\"] = merged_df[\"pagesCount\"].fillna(0).astype(int)\n",
    "\n",
    "column_types = {\n",
    "    \"docID\": \"int\",\n",
    "    \"originYearLate\": \"string\",\n",
    "    \"originYearEarly\": \"string\",\n",
    "    \"pagesCount\": \"string\",\n",
    "    \"leavesCount\": \"string\",\n",
    "    \"century\": \"string\",\n",
    "    \"source\": \"string\",\n",
    "    \"label\": \"string\",\n",
    "}\n",
    "merged_df.astype(column_types)\n",
    "\n",
    "merged_df.to_csv(\"../data/manuscripts_json_tei.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
