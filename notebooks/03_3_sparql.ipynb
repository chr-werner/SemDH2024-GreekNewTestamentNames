{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pandas==2.1.4\n",
    "!{sys.executable} -m pip install requests==2.31.0\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add data from dbpedia\n",
    "\n",
    "### Query, Endpoint and Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e651ac330fcd689c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Your SPARQL query\n",
    "sparql_query = \"\"\"\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX dbc: <http://dbpedia.org/resource/Category:>\n",
    "\n",
    "SELECT DISTINCT ?entry ?entryLabel ?form ?number ?found\n",
    "WHERE {\n",
    "\tVALUES ?concept {\n",
    "\t\tdbc:Greek_New_Testament_lectionaries\n",
    "\t\tdbc:Greek_New_Testament_minuscules\n",
    "\t\tdbc:Greek_New_Testament_uncials\n",
    "\t\tdbc:New_Testament_papyri\n",
    "\t}\n",
    "\t?entry dcterms:subject ?concept .\n",
    "\t\n",
    "\tOPTIONAL{?entry rdfs:label ?entryLabel}\n",
    "\tOPTIONAL{?entry dbp:form ?form}\n",
    "\tOPTIONAL{?entry dbp:number ?number}\n",
    "\tOPTIONAL{?entry dbp:found ?found}\n",
    "\t\n",
    "\tFILTER (langMatches(lang(?entryLabel), \"en\"))\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# DBpedia SPARQL endpoint\n",
    "sparql_endpoint = \"http://dbpedia.org/sparql\"\n",
    "\n",
    "\n",
    "# Set the request parameters\n",
    "params = {\"query\": sparql_query, \"format\": \"json\"}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e814961407be8a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Request data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9e6009860c07ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Send the SPARQL query to DBpedia\n",
    "response = requests.get(sparql_endpoint, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the bindings from the response\n",
    "    bindings = data[\"results\"][\"bindings\"]\n",
    "\n",
    "    # Convert the bindings to a list of dictionaries\n",
    "    results_list = [\n",
    "        {key: binding[key][\"value\"] for key in binding} for binding in bindings\n",
    "    ]\n",
    "\n",
    "    # Create a pandas DataFrame from the list\n",
    "    manuscripts_sparql_df = pd.DataFrame(results_list)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f2613b31c8dbd40",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleanup 'number' column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f184f10de48dc280"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def has_decimal(string: str) -> bool:\n",
    "    value = float(string)\n",
    "    return value % 1 != 0\n",
    "\n",
    "\n",
    "# Custom function to clean and convert values to integers\n",
    "def clean_and_convert(string: str) -> int | None:\n",
    "    try:\n",
    "        if has_decimal(string):\n",
    "            return None\n",
    "        else:\n",
    "            cleaned_value = \"\".join(filter(str.isdigit, string))\n",
    "            return int(cleaned_value) if cleaned_value else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "manuscripts_cleanup1_df = manuscripts_sparql_df.copy()\n",
    "\n",
    "# Apply the custom function to the specified column\n",
    "manuscripts_cleanup1_df[\"number\"] = manuscripts_cleanup1_df[\"number\"].apply(\n",
    "    clean_and_convert\n",
    ")\n",
    "# if a number is greater than 3000 (by mistake) set it to None\n",
    "manuscripts_cleanup1_df.loc[manuscripts_cleanup1_df[\"number\"] > 3000, \"number\"] = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df76be16d162882",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleanup 'found' column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bb58749736a4080"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "manuscripts_cleanup2_df = manuscripts_cleanup1_df.copy()\n",
    "\n",
    "# Fill NaN values in the 'found' column with an empty string\n",
    "manuscripts_cleanup2_df[\"found\"] = (\n",
    "    manuscripts_cleanup2_df[\"found\"].fillna(\"\").astype(str)\n",
    ")\n",
    "# run a groupby to merge found entries of otherwise duplicate rows\n",
    "manuscripts_cleanup2_df = manuscripts_cleanup2_df.groupby(\n",
    "    [\"entry\", \"entryLabel\", \"form\", \"number\"], as_index=False\n",
    ")[\"found\"].agg(\",\".join)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3123469425c75efd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Re)Generate the GA number from manuscript 'number' and 'form'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f06cb04a6f2a036a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Custom function to modify values based on the 'form' column\n",
    "def generate_ga(row):\n",
    "    if pd.notna(row[\"form\"]) and pd.notna(row[\"number\"]):\n",
    "        if row[\"form\"] == \"Papyrus\":\n",
    "            return \"P\" + str(int(row[\"number\"]))\n",
    "        elif row[\"form\"] == \"Uncial\":\n",
    "            return \"0\" + str(int(row[\"number\"]))\n",
    "        elif row[\"form\"] == \"Minuscule\":\n",
    "            return str(int(row[\"number\"]))\n",
    "        elif row[\"form\"] == \"Lectionary\":\n",
    "            return \"L\" + str(int(row[\"number\"]))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "manuscripts_cleanup3_df = manuscripts_cleanup2_df.copy()\n",
    "\n",
    "manuscripts_cleanup3_df[\"ga\"] = manuscripts_cleanup3_df.apply(generate_ga, axis=1)\n",
    "\n",
    "manuscripts_cleanup3_df = manuscripts_cleanup3_df.rename(\n",
    "    columns={\"entry\": \"dbpedia\", \"entryLabel\": \"label\"}\n",
    ")\n",
    "manuscripts_cleanup3_df.drop(labels=[\"number\"], axis=1, inplace=True)\n",
    "manuscripts_cleanup3_df[\"source\"] = \"dbpedia\"\n",
    "\n",
    "manuscripts_cleanup3_df.head(-1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8990ac577d054cea",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge with already known data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da734d852e539c79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read file manuscripts.csv\n",
    "manuscripts_df = pd.read_csv(\"../data/manuscripts_json_tei.csv\")\n",
    "\n",
    "merged_df = pd.concat([manuscripts_df, manuscripts_cleanup3_df], ignore_index=True)\n",
    "\n",
    "merged_df[\"pagesCount\"] = merged_df[\"pagesCount\"].fillna(0).astype(int)\n",
    "\n",
    "column_types = {\n",
    "    \"docID\": \"string\",\n",
    "    \"originYearLate\": \"string\",\n",
    "    \"originYearEarly\": \"string\",\n",
    "    \"pagesCount\": \"string\",\n",
    "    \"leavesCount\": \"string\",\n",
    "    \"century\": \"string\",\n",
    "    \"source\": \"string\",\n",
    "    \"label\": \"string\",\n",
    "    \"dbpedia\": \"string\",\n",
    "    \"found\": \"string\",\n",
    "}\n",
    "merged_df.astype(column_types)\n",
    "\n",
    "# cleanup\n",
    "merged_df[\"originYearLate\"].replace({0: None, 0.0: None}, inplace=True)\n",
    "merged_df[\"originYearEarly\"].replace({0: None, 0.0: None}, inplace=True)\n",
    "merged_df[\"pagesCount\"].replace({0: None, 0.0: None}, inplace=True)\n",
    "merged_df[\"leavesCount\"].replace({0: None, 0.0: None}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54cb91414df89f41",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Writing to file\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcff743e103278eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_df.convert_dtypes().to_csv(\"../data/manuscripts.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f3fe4969d3a95a6",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
